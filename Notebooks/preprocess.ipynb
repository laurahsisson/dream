{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ccb427-ad5b-4673-a458-c2dfe0b12732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_COUNT = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ef7dd2-573a-4648-8f24-27d9a90f8cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mChallenge\u001b[m\u001b[m               dataset_labels_small.h5 pair_huge.json\n",
      "dataset.h5              leaderboard.h5          test.h5\n",
      "dataset_contrast.h5     molecules.csv           train.h5\n",
      "dataset_labels.h5       odor_pair_full.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"Data\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92faae55-af35-4eb6-9312-798cee44f8ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266758,\n",
       " {'mol1': 'CC(=CCC1C(O1)(C)C)C=C',\n",
       "  'mol2': 'CCCC(CC)O',\n",
       "  'blend_notes': ['herbal']})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"pair_huge.json\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "len(dataset),dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed956df4-e2af-467f-b4a5-1fece84c8578",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 266758/266758 [00:00<00:00, 4079500.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['clean',\n",
       " 'vegetable',\n",
       " 'honey',\n",
       " 'fishy',\n",
       " 'lactonic',\n",
       " 'mentholic',\n",
       " 'marine',\n",
       " 'fruity',\n",
       " 'milky',\n",
       " 'mossy',\n",
       " 'tobacco',\n",
       " 'meaty',\n",
       " 'tropical',\n",
       " 'coffee',\n",
       " 'radish',\n",
       " 'floral',\n",
       " 'bready',\n",
       " 'kokumi',\n",
       " 'green',\n",
       " 'alcoholic',\n",
       " 'medicinal',\n",
       " 'sulfurous',\n",
       " 'juicy',\n",
       " 'creamy',\n",
       " 'thujonic',\n",
       " 'terpenic',\n",
       " 'savory',\n",
       " 'apple',\n",
       " 'chocolate',\n",
       " 'anise',\n",
       " 'acrylate',\n",
       " 'naphthyl',\n",
       " 'sweet',\n",
       " 'moldy',\n",
       " 'pungent',\n",
       " 'brown',\n",
       " 'balsamic',\n",
       " 'ammoniacal',\n",
       " 'melon',\n",
       " 'musty',\n",
       " 'aldehydic',\n",
       " 'herbal',\n",
       " 'winey',\n",
       " 'nutty',\n",
       " 'mustard',\n",
       " 'dry',\n",
       " 'rummy',\n",
       " 'cheesy',\n",
       " 'roasted',\n",
       " 'solvent',\n",
       " 'malty',\n",
       " 'salty',\n",
       " 'orris',\n",
       " 'astringent',\n",
       " 'tarragon',\n",
       " 'cocoa',\n",
       " 'jammy',\n",
       " 'vanilla',\n",
       " 'seafood',\n",
       " 'hay',\n",
       " 'sweaty',\n",
       " 'berry',\n",
       " 'coumarinic',\n",
       " 'pine',\n",
       " 'waxy',\n",
       " 'rooty',\n",
       " 'animal',\n",
       " 'toasted',\n",
       " 'corn chip',\n",
       " 'peach',\n",
       " 'aromatic',\n",
       " 'metallic',\n",
       " 'alliaceous',\n",
       " 'celery',\n",
       " 'woody',\n",
       " 'camphoreous',\n",
       " 'estery',\n",
       " 'dusty',\n",
       " 'buttery',\n",
       " 'musk',\n",
       " 'potato',\n",
       " 'popcorn',\n",
       " 'citrus',\n",
       " 'powdery',\n",
       " 'onion',\n",
       " 'wasabi',\n",
       " 'burnt',\n",
       " 'fermented',\n",
       " 'tonka',\n",
       " 'minty',\n",
       " 'corn',\n",
       " 'fatty',\n",
       " 'odorless',\n",
       " 'caramellic',\n",
       " 'whiskey',\n",
       " 'citronella',\n",
       " 'ethereal',\n",
       " 'oily',\n",
       " 'coconut',\n",
       " 'mushroom',\n",
       " 'cooling',\n",
       " 'greasy',\n",
       " 'cabbage',\n",
       " 'ketonic',\n",
       " 'plastic',\n",
       " 'ripe',\n",
       " 'eggy',\n",
       " 'sour',\n",
       " 'leafy',\n",
       " 'amber',\n",
       " 'cherry',\n",
       " 'cucumber',\n",
       " 'licorice',\n",
       " 'dairy',\n",
       " 'garlic',\n",
       " 'chemical',\n",
       " 'spicy',\n",
       " 'smoky',\n",
       " 'earthy',\n",
       " 'fresh',\n",
       " 'yeasty',\n",
       " 'bitter',\n",
       " 'leathery',\n",
       " 'fungal',\n",
       " 'tomato',\n",
       " 'acetic',\n",
       " 'fusel',\n",
       " 'acidic',\n",
       " 'phenolic',\n",
       " 'soapy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "all_notes = set()\n",
    "for d in tqdm.tqdm(dataset):\n",
    "    all_notes.update(d[\"blend_notes\"])\n",
    "all_notes = list(all_notes)\n",
    "\n",
    "all_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a7b991-091c-4ab8-bd29-66141f05234a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 266758/266758 [00:01<00:00, 213070.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(('CC(=CCC1C(O1)(C)C)C=C', 'CCCC(CC)O'),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Create a dictionary mapping each label to a unique index\n",
    "label_to_index = {label: idx for idx, label in enumerate(all_notes)}\n",
    "\n",
    "def multi_hot(notes):\n",
    "    # Initialize a zero tensor of the appropriate size\n",
    "    multi_hot_vector = torch.zeros(len(all_notes))\n",
    "\n",
    "    # Set the corresponding positions in the tensor to 1 for each label of the item\n",
    "    for label in notes:\n",
    "        index = label_to_index[label]\n",
    "        multi_hot_vector[index] = 1\n",
    "    return multi_hot_vector\n",
    "\n",
    "all_multihots = dict()\n",
    "for d in tqdm.tqdm(dataset):\n",
    "    all_multihots[(d[\"mol1\"],d[\"mol2\"])] = multi_hot(d[\"blend_notes\"])\n",
    "next(iter(all_multihots.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b14e79e-8ef3-4bff-91e0-bd3864b642f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 266758/266758 [00:00<00:00, 2569083.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6850, 4384)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "notes_to_pairs = collections.defaultdict(list)\n",
    "for d in tqdm.tqdm(dataset):\n",
    "    notes_to_pairs[frozenset(d[\"blend_notes\"])].append((d[\"mol1\"],d[\"mol2\"]))\n",
    "\n",
    "len(notes_to_pairs), len(next(iter(notes_to_pairs.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8cbed91-bd9a-4a8c-ae60-d9e948e16a10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 6850/6850 [00:02<00:00, 3155.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(266758,\n",
       " (('CC(=CCC1C(O1)(C)C)C=C', 'CCCC(CC)O'),\n",
       "  [('CC(=O)OC1(CCCCC1)C#C', 'CC1(C2CCC(C2)(C1=O)C)C'),\n",
       "   ('CC(=CCC1C(O1)(C)C)C=C', 'CC1=CC2C(C2(C)C)CC1C(=O)C'),\n",
       "   ('CC(=CCCC(C)(C=C)OC=O)C', 'CC(C)C(=O)OC1CCC2CCCCC2C1'),\n",
       "   ('C[C@]1([C@H](CCC(O1)(C)C)O)C=C', 'O=COC/C(=C\\\\c1ccccc1)CCCCC'),\n",
       "   ('CC(C)C1=CC(=O)C(=CC=C1)O', 'CC(C)C1C(COCO1)(C)C'),\n",
       "   ('CC(=O)C1=CN=CC=C1', 'CC1CC(CC(=O)O1)(C)C'),\n",
       "   ('CC(CCOC(=O)C)CC(C)(C)C', 'CCCCC(=O)OCC'),\n",
       "   ('CC(=CC(=O)OCCC1=CC=CC=C1)C', 'CC(CCC=C(C)C)CC(=O)OC'),\n",
       "   ('CC(C)/C=C/CCCCC(=O)NCC1=CC(=C(C=C1)O)OC', 'C\\\\C=C(/C)\\\\C(=O)OCCC(C)C'),\n",
       "   ('CC(C)C1=CC=C(C=C1)COC(=O)C', 'CCCCC(CO)C(=O)C'),\n",
       "   ('CC(=CC(=O)OCCC1=CC=CC=C1)C', 'CCCCCO'),\n",
       "   ('CC(C)(C=C)O', 'CCC1OCC2(CC(=CCC2C)C)CO1'),\n",
       "   ('CC(CCOC=O)CC(C)(C)C', 'CC1(C2CCC(=C)C1C2)C'),\n",
       "   ('CC(C)C/C=C(\\\\COC(=O)C)/C(C)C', 'CCNC(=O)C1CC(CCC1C(C)C)C'),\n",
       "   ('COC1=C2C(=C(C(=C1)CC=C)OC)OCO2',\n",
       "    'C[C@@H]1CC[C@H]2[C@@H]1C3[C@H](C3(C)C)CC[C@]2(C)O'),\n",
       "   ('CC(C)C1C(COCO1)(C)C', 'CC1=CCC2(C1C2)C(C)C'),\n",
       "   ('CC(=O)OC1CC2CC1C3C2CCC3', 'CCCCCCOC=O'),\n",
       "   ('CC1=CCCC(C1C(=O)OC)(C)C', 'c3oc(Cc2cc(Cc1ccco1)oc2)cc3'),\n",
       "   ('CC1(C)C2CC1C3(CC2)CO3', 'CC1CC2(CCCCC2)OC=C1'),\n",
       "   ('CC1(CC[C@@H]([C@](O1)(C)C=C)O)C', 'CC1=CC2C(C2(C)C)CC1C(=O)C'),\n",
       "   ('CC=CC(=O)OCC1=CC=CC=C1', 'CCCCC(CO)C(=O)C'),\n",
       "   ('CC(C)C(=O)OC(C)CC(=C)C', 'CC(C)C=O'),\n",
       "   ('CC1=C(C=C(C=C1)C(C)C)OC', 'CCCCC1OC(CC(O1)(C)C)C'),\n",
       "   ('CC(C)C(=O)OC(C)CC(=C)C', 'C[C@]1(CC[C@@H](O1)C(C)(C)O)C=C'),\n",
       "   ('CCCC(=O)OC1CC2CCC1(C2(C)C)C', 'CCO[C@@H]1C[C@@H](CC(C1)(C)C)C')]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "positives = dict()\n",
    "for n, pairs in tqdm.tqdm(notes_to_pairs.items()):\n",
    "    for p1 in pairs:\n",
    "        vals = list(random.sample(pairs,MAX_COUNT)) if len(pairs) > MAX_COUNT else pairs\n",
    "        positives[p1] = [p2 for p2 in vals if p1 != p2]\n",
    "len(positives), next(iter(positives.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed9c017-70c7-480d-9d64-dfde97a9c039",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32712, 0.12262799991003082)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = len([p for p, ps in positives.items() if len(ps) < MAX_COUNT])\n",
    "missing, missing/len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa8e6da0-3f52-47ef-8cd7-0aad708e7df4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mol_sets = collections.defaultdict(list)\n",
    "for i,d in enumerate(dataset):\n",
    "    mol_sets[d[\"mol1\"]].append(i)\n",
    "    mol_sets[d[\"mol2\"]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa4e4f16-f990-479f-93c8-6bf9b05db141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairs = []\n",
    "pair_to_notes = dict()\n",
    "for d in dataset:\n",
    "    pair = (d[\"mol1\"],d[\"mol2\"])\n",
    "    pairs.append(pair)\n",
    "    pair_to_notes[pair] = set(d[\"blend_notes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca624953-af2e-494a-971b-a8d4838f6343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notes_sets = dict()\n",
    "for i,d in enumerate(dataset):\n",
    "    notes_sets[i] = set(d[\"blend_notes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0df44fb1-f4e8-482a-9d5f-73a12a118188",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 3428/3428 [00:25<00:00, 136.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "266242"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hard negatives are anchor/negatives that share a molecule\n",
    "# but do not have any notes in common.\n",
    "negatives = collections.defaultdict(list)\n",
    "for (mol,idcs) in tqdm.tqdm(mol_sets.items()):\n",
    "    for i in idcs:\n",
    "        p1 = notes_sets[i]\n",
    "        for j in idcs:\n",
    "            p2 = notes_sets[j]\n",
    "            if bool(p1 & p2):\n",
    "                continue\n",
    "            negatives[pairs[i]].append(pairs[j])\n",
    "len(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "745b2a3c-b0cd-4149-94ae-d3f49bd575c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15554, 0.058307529671087654)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = len([p for p, ns in negatives.items() if len(ns) < MAX_COUNT])\n",
    "missing, missing/len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5708355-eb22-4c7d-8791-4d7902881ada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Supplement with random negatives if we have less than the required\n",
    "# # number of hard negatives.\n",
    "# for p, ns in tqdm.tqdm(negatives.items()):\n",
    "#     notes = pair_to_notes[pair]\n",
    "#     while len(ns) < MAX_COUNT:\n",
    "#         other = random.choice(dataset)\n",
    "#         other_pair = (other[\"mol1\"],other[\"mol2\"])\n",
    "#         other_notes = pair_to_notes[other_pair]\n",
    "#         if bool(notes & other_notes):\n",
    "#             continue\n",
    "#         ns.append(other_pair)\n",
    "#     negatives[p] = list(random.sample(pairs,MAX_COUNT))\n",
    "\n",
    "# missing = len([p for p, ns in negatives.items() if len(ns) != MAX_COUNT])\n",
    "# len(negatives), missing, missing/len(dataset)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f7c8231-efec-4962-a612-8e483946c682",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('CC(=CCC1C(O1)(C)C)C=C', 'CCCC(CC)O'),\n",
       " [('CC(=CCC1C(O1)(C)C)C=C', 'CCOC(C)(CCC=C(C)C)C=C'),\n",
       "  ('CC(=CCC1C(O1)(C)C)C=C', 'CC/C=C\\\\CCOC(=O)C1=CC=CC=C1O'),\n",
       "  ('CC(=CCC1C(O1)(C)C)C=C', 'CC(C)(CCC1CCCCC1)O'),\n",
       "  ('CC(=CCC1C(O1)(C)C)C=C', 'CC(=CCC[C@@](C)(C=C)O)C'),\n",
       "  ('CC(=CCC1C(O1)(C)C)C=C', 'CCOC(C)OC(C)(CCC=C(C)C)C=C'),\n",
       "  ('CC(=CCC1C(O1)(C)C)C=C', 'CC/C(=C/CCC(C)(C=C)OC(=O)C)/C'),\n",
       "  ('CC(=CCC1C(O1)(C)C)C=C', 'CC/C(=C/CCC(C)(C=C)O)/C'),\n",
       "  ('CC(=CCC1C(O1)(C)C)C=C', 'CCC(C)(CCC=C(C)C)O'),\n",
       "  ('CC(=CCC1C(O1)(C)C)C=C', 'CC1CCOC(C1)CC(C)C'),\n",
       "  ('CC(=CCC1C(O1)(C)C)C=C', 'CC1=CCC(=C(C)CCC=C(C)C)CC1'),\n",
       "  ('CC(=CCC1C(O1)(C)C)C=C', 'CCCCCCCCOC(=O)CC1=CC=CC=C1'),\n",
       "  ('CC(=CCC1C(O1)(C)C)C=C', 'CC1(CCC(C23C14C2CC(C4)C3(C)C)COC=O)C'),\n",
       "  ('CC(=CCC1C(O1)(C)C)C=C', 'CCC(C)(CCCC(C)C)O'),\n",
       "  ('CC(=O)OCC1CCC(C23C14C2CC(C3)C4(C)C)(C)C', 'CCCC(CC)O'),\n",
       "  ('CCC(C)C=O', 'CCCC(CC)O'),\n",
       "  ('CC1(CCC(C23C14C2CC(C4)C3(C)C)CO)C', 'CCCC(CC)O'),\n",
       "  ('CCCC(CC)O', 'CCOC(=O)C(C)C'),\n",
       "  ('CCCC(CC)O', 'C[C@]12CCCC(C1CC[C@@]([C@@H]2CC[C@](C)(C=C)O)(C)O)(C)C'),\n",
       "  ('CC1(CCC(C23C14C2CC(C4)C3(C)C)COC=O)C', 'CCCC(CC)O'),\n",
       "  ('CCCC(CC)O', 'CCO'),\n",
       "  ('CCCC(CC)O', 'CCOC(C)OCC'),\n",
       "  ('CCCC(=O)C=CC', 'CCCC(CC)O'),\n",
       "  ('CCCC(CC)O', 'CCCCOC(C)OCC'),\n",
       "  ('CC/C=C\\\\CO', 'CCCC(CC)O'),\n",
       "  ('CCC/C=C/COC=O', 'CCCC(CC)O'),\n",
       "  ('CCCC(CC)O', 'CC\\\\C=C\\\\CC(=O)OCC'),\n",
       "  ('CC1=CC(=C(C=C1)C)O', 'CCCC(CC)O'),\n",
       "  ('CC1CCCC(=O)C1', 'CCCC(CC)O'),\n",
       "  ('CC(=CCC/C(=C/COC(=O)C1=CC=CC=C1N)/C)C', 'CCCC(CC)O'),\n",
       "  ('C1=CNC=C1', 'CCCC(CC)O'),\n",
       "  ('CC=O', 'CCCC(CC)O'),\n",
       "  ('CCCC(CC)O', 'CCCO'),\n",
       "  ('CCC/C=C/C=O', 'CCCC(CC)O'),\n",
       "  ('CC1=CC2=C(C=C1)C(CC=C2)(C)C', 'CCCC(CC)O')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(negatives.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "051ac0a1-f2a0-445b-a243-6546e2d5d2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3428, 'CCC=CCCC=CC=O')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_smiles = set()\n",
    "for d in dataset:\n",
    "    all_smiles.add(d[\"mol1\"])\n",
    "    all_smiles.add(d[\"mol2\"])\n",
    "len(all_smiles),next(iter(all_smiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aedac74b-2a79-4699-8a77-d730ea4ca321",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                | 0/3428 [00:00<?, ?it/s][12:32:43] SMILES Parse Error: syntax error while parsing: InChI=1/C7H8S/c1-6-4-2-3-5-7(6)8/h2-5,8H,1H3\n",
      "[12:32:43] SMILES Parse Error: Failed parsing SMILES 'InChI=1/C7H8S/c1-6-4-2-3-5-7(6)8/h2-5,8H,1H3' for input: 'InChI=1/C7H8S/c1-6-4-2-3-5-7(6)8/h2-5,8H,1H3'\n",
      " 44%|███████████████▎                   | 1505/3428 [00:01<00:01, 1009.35it/s][12:32:44] SMILES Parse Error: syntax error while parsing: (C)C1=CN=CC(=N1)OC.CC(C)C1=CN=C(C=N1)OC.CC(C)C1=NC=CN=C1OC\n",
      "[12:32:44] SMILES Parse Error: Failed parsing SMILES '(C)C1=CN=CC(=N1)OC.CC(C)C1=CN=C(C=N1)OC.CC(C)C1=NC=CN=C1OC' for input: '(C)C1=CN=CC(=N1)OC.CC(C)C1=CN=C(C=N1)OC.CC(C)C1=NC=CN=C1OC'\n",
      "[12:32:44] Can't kekulize mol.  Unkekulized atoms: 3 4 5 6 8\n",
      "100%|████████████████████████████████████| 3428/3428 [00:03<00:00, 995.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " 3425,\n",
       " ('CCC=CCCC=CC=O', Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3])))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ogb.utils import smiles2graph\n",
    "from torch_geometric.data import InMemoryDataset, download_url, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "def to_torch(graph):\n",
    "    tensor_keys = [\"edge_index\", 'edge_feat', 'node_feat']\n",
    "    for key in tensor_keys:\n",
    "        graph[key] = torch.from_numpy(graph[key])\n",
    "    return Data(x=graph[\"node_feat\"].float(),edge_attr=graph[\"edge_feat\"],edge_index=graph[\"edge_index\"])\n",
    "\n",
    "errored = 0\n",
    "graph_data = dict()\n",
    "for smiles in tqdm.tqdm(all_smiles):\n",
    "    try:\n",
    "        graph_data[smiles] = to_torch(smiles2graph(smiles))\n",
    "    except AttributeError as e:\n",
    "        errored += 1\n",
    "errored, len(graph_data), next(iter(graph_data.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e091e5a-2d74-461e-bb1b-3f3d586e4c53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 266758/266758 [01:02<00:00, 4243.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(266450,\n",
       " (('CC(=CCC1C(O1)(C)C)C=C', 'CCCC(CC)O'),\n",
       "  BlendData(x=[18, 9], edge_index=[2, 34], edge_attr=[34, 3], mol_batch=[18], blend_batch=[2])))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import data\n",
    "\n",
    "pair_to_data = dict()\n",
    "for d in tqdm.tqdm(dataset):\n",
    "    if not d[\"mol1\"] in graph_data or not d[\"mol2\"] in graph_data:\n",
    "        continue\n",
    "    pair = (d[\"mol1\"],d[\"mol2\"])\n",
    "    g1 = graph_data[d[\"mol1\"]]\n",
    "    g2 = graph_data[d[\"mol2\"]]\n",
    "    pair_to_data[pair] = data.combine_graphs([g1,g2])\n",
    "len(pair_to_data), next(iter(pair_to_data.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6535d22-9952-43a9-921f-e4d22a716b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265934, 0.9969110579626478)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_pairs = set(pair_to_data.keys()).intersection(set(positives.keys())).intersection(set(negatives.keys())).intersection(set(all_multihots.keys()))\n",
    "len(valid_pairs), len(valid_pairs)/len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2398153-81e8-4e40-8c01-82898fd7f2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▏                              | 10001/266450 [00:05<02:16, 1879.35it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import h5py\n",
    "import base64\n",
    "\n",
    "def encode_smiles(smiles):\n",
    "    return base64.urlsafe_b64encode(smiles.encode()).decode()\n",
    "\n",
    "with h5py.File('dataset_labels_small.h5', 'w') as f:\n",
    "    for i, (pair, data) in enumerate(tqdm.tqdm(pair_to_data.items())):\n",
    "        if i > 10000:\n",
    "            break\n",
    "        group = f.create_group(encode_smiles(json.dumps(pair)))\n",
    "        group.create_dataset(\"pair\",data=pairs[i])\n",
    "        group.create_dataset(\"notes\",data=all_multihots[pair].numpy())\n",
    "        graph_group = group.create_group(\"graph\")\n",
    "        for k,v in data.items():\n",
    "            graph_group.create_dataset(k,data=v.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f367404-f81a-4cdf-a4f7-92692743a231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 266450/266450 [03:31<00:00, 1257.28it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import h5py\n",
    "import base64\n",
    "\n",
    "def encode_smiles(smiles):\n",
    "    return base64.urlsafe_b64encode(smiles.encode()).decode()\n",
    "\n",
    "with h5py.File('dataset_labels.h5', 'w') as f:\n",
    "    for i, (pair, data) in enumerate(tqdm.tqdm(pair_to_data.items())):\n",
    "        group = f.create_group(encode_smiles(json.dumps(pair)))\n",
    "        group.create_dataset(\"pair\",data=pairs[i])\n",
    "        group.create_dataset(\"notes\",data=all_multihots[pair].numpy())\n",
    "        graph_group = group.create_group(\"graph\")\n",
    "        for k,v in data.items():\n",
    "            graph_group.create_dataset(k,data=v.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca75c3fa-24b8-40f4-8f91-ecd534e1cc8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 266450/266450 [06:39<00:00, 666.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import h5py\n",
    "import base64\n",
    "\n",
    "def encode_smiles(smiles):\n",
    "    return base64.urlsafe_b64encode(smiles.encode()).decode()\n",
    "\n",
    "with h5py.File('dataset_contrast.h5', 'w') as f:\n",
    "    for i, (pair, data) in enumerate(tqdm.tqdm(pair_to_data.items())):\n",
    "        group = f.create_group(encode_smiles(json.dumps(pair)))\n",
    "        group.create_dataset(\"pair\",data=pairs[i])\n",
    "        group.create_dataset(\"positives\",data=positives[pair])\n",
    "        group.create_dataset(\"negatives\",data=negatives[pair])\n",
    "        graph_group = group.create_group(\"graph\")\n",
    "        for k,v in data.items():\n",
    "            graph_group.create_dataset(k,data=v.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
