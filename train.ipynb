{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9d0475-a1a3-497a-87af-98907e71fdc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██                                 | 10001/166733 [00:15<04:08, 631.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import h5py\n",
    "import base64\n",
    "import tqdm\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "import numpy as np\n",
    "\n",
    "def decode_smiles(encoded):\n",
    "    return base64.urlsafe_b64decode(encoded.encode()).decode()\n",
    "\n",
    "dataset = dict()\n",
    "with h5py.File('Data/dataset.h5', 'r') as f:\n",
    "    for i, encoded_pair in enumerate(tqdm.tqdm(f.keys())):\n",
    "        pair_str = decode_smiles(encoded_pair)\n",
    "        pair = json.loads(pair_str)\n",
    "        \n",
    "        group = f[encoded_pair]\n",
    "        \n",
    "        positives = group['positives'][:].astype(str).tolist()\n",
    "        negatives = group['negatives'][:].astype(str).tolist()\n",
    "        \n",
    "        graph_group = group['graph']\n",
    "        graph_data = {k: torch.tensor(np.array(v)) for k, v in graph_group.items()}\n",
    "        graph_data = {k: v.float() if k != \"edge_index\" else v.long() for k, v in graph_data.items()}\n",
    "        \n",
    "        dataset[tuple(pair)] = {\"positives\":positives, \"negatives\":negatives, \"graph\": tg.data.Data(**graph_data)}\n",
    "        \n",
    "        if i > 10000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68080cea-1111-4521-812c-5058ba05a063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The ordering of the graphs in this is arbitrary (alphabetically based on SMILES)\n",
    "# but the logistic predictor does rely on this ordering.\n",
    "class PairData(tg.data.Data):\n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        if key == 'edge_index_anchor':\n",
    "            return self.x_anchor.size(0)\n",
    "        if key == 'edge_index_positive':\n",
    "            return self.x_positive.size(0)\n",
    "        return super().__inc__(key, value, *args, **kwargs)\n",
    "\n",
    "    def __cat_dim__(self, key, value, *args, **kwargs):\n",
    "        if key == 'y':\n",
    "            return None\n",
    "        return super().__cat_dim__(key, value, *args, **kwargs)\n",
    "    \n",
    "def make_pair_data(anchor_graph,positive_graph):\n",
    "    return PairData(x_anchor=anchor_graph[\"x\"].float(),\n",
    "                  edge_attr_anchor=anchor_graph[\"edge_attr\"].float(),\n",
    "                  edge_index_anchor=anchor_graph[\"edge_index\"],\n",
    "                  x_positive=positive_graph[\"x\"].float(),\n",
    "                  edge_attr_positive=positive_graph[\"edge_attr\"].float(),\n",
    "                  edge_index_positive=positive_graph[\"edge_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a496bf66-ba6f-4486-9a7d-a3606b9cf935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_in_dataset(pair,key):\n",
    "    positive = \"\"\n",
    "    i = 0\n",
    "    # TODO: Remove this once we load in all data\n",
    "    while not positive in dataset:\n",
    "        positive = tuple(random.choice(dataset[pair][key]))\n",
    "        i += 1\n",
    "        if i > 10000:\n",
    "            print(\"FAILED\")\n",
    "            break\n",
    "    positive_graph = dataset[positive][\"graph\"]\n",
    "    return positive_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5ce5fc-1791-475b-961d-e149bc2b4ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.data import Dataset\n",
    "\n",
    "def triplet_graph_generator(to_yield,num_negatives):\n",
    "    for i, (pair, data) in enumerate(dataset.items()):\n",
    "        if i >= to_yield:\n",
    "            break\n",
    "\n",
    "        anchor = data[\"graph\"]\n",
    "        \n",
    "        positive = get_in_dataset(pair,\"positives\")\n",
    "        \n",
    "        negatives = [get_in_dataset(pair,\"negatives\") for _ in range(num_negatives)]\n",
    "        \n",
    "        yield anchor, positive, negatives\n",
    "        \n",
    "\n",
    "class TripletGraphDataset(Dataset):\n",
    "    def __init__(self, generator_func, to_yield, num_negatives):\n",
    "        super(TripletGraphDataset, self).__init__()\n",
    "        self.generator_func = generator_func\n",
    "        self.data_list = list(generator_func(to_yield, num_negatives))  # Converting generator to list for len() support\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        anchor, positive, negatives = self.data_list[idx]\n",
    "        return anchor, positive, negatives\n",
    "\n",
    "\n",
    "def triplet_collate_fn(batch):\n",
    "    anchors, positives, negatives = [], [], []\n",
    "    for anchor, positive, neg_list in batch:\n",
    "        anchors.append(anchor)\n",
    "        positives.append(positive)\n",
    "        negatives.extend(neg_list)\n",
    "    return Batch.from_data_list(anchors), Batch.from_data_list(positives), Batch.from_data_list(negatives)\n",
    "\n",
    "# Need to switch the number of negatives over time (this will mean lowering bsz)\n",
    "# Create an instance of the custom dataset\n",
    "triplet_dataset = TripletGraphDataset(triplet_graph_generator,16,0)\n",
    "\n",
    "# Create a DataLoader with a custom collate function\n",
    "dataloader = DataLoader(triplet_dataset, batch_size=4, shuffle=True, collate_fn=triplet_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47fbaa78-54ed-4a0d-9db5-90f97d220ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': '2,230,912',\n",
       " 'project_node_feats': '1,280',\n",
       " 'gnn_layer': '2,130,560',\n",
       " 'gru': '99,072',\n",
       " 'final_dropout': '0'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(module):\n",
    "    return \"{:,}\".format(sum(p.numel() for p in module.parameters()))\n",
    "\n",
    "def readout_counts(module):\n",
    "    results = {\"total\":count_parameters(module)}\n",
    "    for n, c in module.named_children():\n",
    "        results[n] = count_parameters(c)\n",
    "    return results\n",
    "readout_counts(model.conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bcdcbb1-ef16-40d6-9b06-d096cb28b89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "{'total': '2,660,352', 'conv': '2,230,912', 'readout': '429,440'}\n",
      "{'total': '2,230,912', 'project_node_feats': '1,280', 'gnn_layer': '2,130,560', 'gru': '99,072', 'final_dropout': '0'}\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Shamelessly stolen from (converted to PytorchGeometric)\n",
    "# https://lifesci.dgl.ai/_modules/dgllife/model/gnn/mpnn.html\n",
    "class MPNNGNN(nn.Module):\n",
    "    \"\"\"MPNN.\n",
    "\n",
    "    MPNN is introduced in `Neural Message Passing for Quantum Chemistry\n",
    "    <https://arxiv.org/abs/1704.01212>`__.\n",
    "\n",
    "    This class performs message passing in MPNN and returns the updated node representations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    node_in_feats : int\n",
    "        Size for the input node features.\n",
    "    node_out_feats : int\n",
    "        Size for the output node representations. Default to 64.\n",
    "    edge_in_feats : int\n",
    "        Size for the input edge features. Default to 128.\n",
    "    edge_hidden_feats : int\n",
    "        Size for the hidden edge representations.\n",
    "    num_step_message_passing : int\n",
    "        Number of message passing steps. Default to 6.\n",
    "    \"\"\"\n",
    "    def __init__(self, node_in_feats, edge_in_feats, node_out_feats=64,\n",
    "                 edge_hidden_feats=128, num_step_message_passing=6, dropout=0.1):\n",
    "        super(MPNNGNN, self).__init__()\n",
    "\n",
    "        # This should be changed to node wise dropout. But maybe not?\n",
    "        # See https://arxiv.org/pdf/1411.4280        \n",
    "        self.project_node_feats = nn.Sequential(\n",
    "            nn.Linear(node_in_feats, node_out_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.num_step_message_passing = num_step_message_passing\n",
    "        edge_network = nn.Sequential(\n",
    "            nn.Linear(edge_in_feats, edge_hidden_feats),\n",
    "            nn.ReLU(), # Could add dropout after this.\n",
    "            nn.Linear(edge_hidden_feats, node_out_feats * node_out_feats),\n",
    "            nn.Dropout(dropout) # This one is after the largest by far.\n",
    "        )\n",
    "\n",
    "        self.gnn_layer = tg.nn.conv.NNConv(\n",
    "            in_channels=node_out_feats,\n",
    "            out_channels=node_out_feats,\n",
    "            nn=edge_network,\n",
    "            aggregator_type='sum'\n",
    "        )\n",
    "\n",
    "        # If we add a second layer, we could add dropout.\n",
    "        self.gru = nn.GRU(node_out_feats, node_out_feats,bidirectional=False)\n",
    "        self.final_dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, graph):\n",
    "        \"\"\"Performs message passing and updates node representations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        g : DGLGraph\n",
    "            DGLGraph for a batch of graphs.\n",
    "        node_feats : float32 tensor of shape (V, node_in_feats)\n",
    "            Input node features. V for the number of nodes in the batch of graphs.\n",
    "        edge_feats : float32 tensor of shape (E, edge_in_feats)\n",
    "            Input edge features. E for the number of edges in the batch of graphs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        node_feats : float32 tensor of shape (V, node_out_feats)\n",
    "            Output node representations.\n",
    "        \"\"\"\n",
    "        node_feats = graph.x\n",
    "        edge_feats = graph.edge_attr\n",
    "        node_feats = self.project_node_feats(node_feats) # (V, node_out_feats)\n",
    "        hidden_feats = node_feats.unsqueeze(0)           # (1, V, node_out_feats)\n",
    "\n",
    "        for _ in range(self.num_step_message_passing):\n",
    "            node_feats = F.relu(self.gnn_layer(node_feats, graph.edge_index, edge_feats))\n",
    "            node_feats, hidden_feats = self.gru(node_feats.unsqueeze(0), hidden_feats)\n",
    "            node_feats = self.final_dropout(node_feats.squeeze(0))\n",
    "\n",
    "        return node_feats\n",
    "\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self,node_out_feats=128,edge_hidden_feats=128,num_step_message_passing=5,dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv = MPNNGNN(node_in_feats=9,edge_in_feats=3,node_out_feats=node_out_feats,edge_hidden_feats=edge_hidden_feats,num_step_message_passing=num_step_message_passing,dropout=dropout)\n",
    "        # https://github.com/davidbuterez/multi-fidelity-gnns-for-drug-discovery-and-quantum-mechanics/blob/3f39d12b66447f62960bf9e4b45070b266328555/schnet_multiple_fidelities/schnet_high_fidelity.py#L159\n",
    "        self.readout = tg.nn.aggr.set_transformer.SetTransformerAggregation(node_out_feats,heads=8,num_encoder_blocks=2,num_decoder_blocks=2,dropout=dropout)\n",
    "\n",
    "    def forward(self,graph):\n",
    "        x = self.conv(graph)\n",
    "        if \"batch\" in graph:\n",
    "            return self.readout(x,graph.batch)\n",
    "        return self.readout(x)\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        return {\"total\":count_parameters(self), \"conv\":count_parameters(self.conv), \"readout\":count_parameters(self.readout)}\n",
    "    \n",
    "# model = Encoder()\n",
    "# model(example[\"graph\"])\n",
    "\n",
    "model = Encoder()\n",
    "# Forward pass through the NNConv layer\n",
    "\n",
    "\n",
    "\n",
    "example = next(iter(dataset.values()))\n",
    "print(model(example[\"graph\"]).shape)\n",
    "print(readout_counts(model))\n",
    "print(readout_counts(model.conv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a132fe73-4a6a-4e41-8fb2-e957090bf2ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import info_nce\n",
    "loss_fn = info_nce.InfoNCE()\n",
    "# Training loop\n",
    "for anchors, positives, negatives in dataloader:\n",
    "    anchor_embeds = model(anchors)\n",
    "    positives_embeds = model(positives)\n",
    "    loss = loss_fn(anchor_embeds,positives_embeds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
