{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3077ca49-b9e7-4fb0-a3a1-bd7c25ce26a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tokenizer\n",
    "import torch\n",
    "\n",
    "graph_tokenizer = tokenizer.GraphTokenizer(torch.load(\"dictionary.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5230b142-7b8d-43d8-bbcf-09e224afab87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 500/500 [00:00<00:00, 920.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'graph1': BlendData(x=[254, 9], edge_index=[2, 476], edge_attr=[476, 3], blend_batch=[28], mol_batch=[254]),\n",
       " 'graph2': BlendData(x=[239, 9], edge_index=[2, 452], edge_attr=[452, 3], blend_batch=[28], mol_batch=[239]),\n",
       " 'y': tensor(0.5769)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import data\n",
    "import torch_geometric as tg\n",
    "\n",
    "all_data = []\n",
    "with h5py.File('Data/train.h5', 'r') as f:\n",
    "    for label in tqdm.tqdm(f.keys()):\n",
    "        group = f[label]\n",
    "        graph1 = data.read_graph(group['graph1'])\n",
    "        graph2 = data.read_graph(group['graph2'])\n",
    "        # Index using () for scalar dataset\n",
    "        y = group[\"y\"][()]\n",
    "        all_data.append({\"graph1\":graph1,\"graph2\":graph2,\"y\":torch.tensor(y)})\n",
    "\n",
    "all_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3cba35-3131-4003-badd-948fac53d66e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlendData(x=[254], edge_index=[2, 476], edge_attr=[476], blend_batch=[28], mol_batch=[254])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tokenizer.tokenize(all_data[0][\"graph1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e69607-d2d3-4061-9e13-bd2bc6401ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9])\n",
      "torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "import aggregate\n",
    "\n",
    "agg = aggregate.BlendAggregator(True,9,1,1,0)\n",
    "from torch_geometric.loader import DataLoader\n",
    "batch = next(iter(DataLoader([all_data[0][\"graph1\"],all_data[0][\"graph2\"]],batch_size=2)))\n",
    "print(agg(batch.x,batch).shape)\n",
    "print(agg(all_data[0][\"graph1\"].x,all_data[0][\"graph1\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a0f70a-86f6-48ee-bbf6-b91316daf606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9])\n",
      "torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "import aggregate\n",
    "\n",
    "agg = aggregate.BlendAggregator(False,9,1,1,0)\n",
    "from torch_geometric.loader import DataLoader\n",
    "batch = next(iter(DataLoader([all_data[0][\"graph1\"],all_data[0][\"graph2\"]],batch_size=2)))\n",
    "print(agg(batch.x,batch).shape)\n",
    "print(agg(all_data[0][\"graph1\"].x,all_data[0][\"graph1\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e7f2dcb-0f2a-4b1a-a6a0-2e1cd0eca8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1041,  0.3365,  0.0174,  ...,  0.2844, -0.0000,  0.1039],\n",
       "         [-0.1871,  0.3660, -0.0453,  ...,  0.3649, -0.1400,  0.2395],\n",
       "         [-0.2525,  0.3784, -0.0000,  ...,  0.0000, -0.0000,  0.2323],\n",
       "         ...,\n",
       "         [-0.4904,  0.2055, -0.3225,  ...,  0.7239, -0.0000,  0.7296],\n",
       "         [-0.3014,  0.3132, -0.1970,  ...,  0.3428, -0.1677,  0.0000],\n",
       "         [-0.1738,  0.2647, -0.0656,  ...,  0.3084, -0.0000,  0.1603]],\n",
       "        grad_fn=<MulBackward0>),\n",
       " tensor([[ 0.2465, -0.2977,  0.0166,  ...,  0.0000,  0.0756,  0.1721],\n",
       "         [ 0.2352, -0.2759, -0.0417,  ...,  0.1757,  0.0000,  0.1873],\n",
       "         [ 0.2047, -0.2888, -0.0505,  ...,  0.1421,  0.0282,  0.1918],\n",
       "         ...,\n",
       "         [ 0.2390, -0.2703, -0.0639,  ...,  0.1028,  0.0587,  0.1232],\n",
       "         [ 0.2472, -0.2958, -0.0105,  ...,  0.1546,  0.0464,  0.1766],\n",
       "         [ 0.2118, -0.2945,  0.0156,  ...,  0.0752,  0.0841,  0.1985]],\n",
       "        grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mpnn\n",
    "\n",
    "config = mpnn.Config(node_out_feats=16,\n",
    "                 edge_hidden_feats=16, num_step_message_passing=3)\n",
    "model = mpnn.from_config(config,node_in_feats=9, edge_in_feats=3,dropout=.1, do_edge_update=True)\n",
    "exmpl = all_data[0][\"graph1\"]\n",
    "model(exmpl,exmpl.x,exmpl.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c24bc1dd-5210-45c8-8bb1-a8615e7fe1a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': '12,224',\n",
       " 'base': '6,480',\n",
       " 'project_edge_feats': '64',\n",
       " 'edge_update_network': '1,056',\n",
       " 'gnn_layer': '4,624'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "utils.readout_counts(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb40fa2f-d978-48ba-bd80-aa02a7061ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 14.5679,  15.0214,  15.6756,   6.8135,  32.3703,   8.4644,   2.6436,\n",
       "          -3.7035,  27.7643,  39.0933,  -3.1549,  -7.7342,  44.6607,  37.7973,\n",
       "          22.1152,  22.6417,  26.5870,  10.7395,  21.6800,  -8.5880,  16.7585,\n",
       "          27.6666,  12.2636,  41.1406, -17.0898,  12.3411,  29.1615,  26.2636,\n",
       "           7.9025,  23.8421, -11.4530,  19.8079,  19.0724,   6.8836,  15.0650,\n",
       "          14.7421,   7.1672,   5.5850,   7.1261,  22.0255,  12.7941,   4.8541,\n",
       "          34.4244,  26.3723,   9.7602,  18.0545,  -5.5065,  22.9658,  -7.0983,\n",
       "           5.3882,   3.7933,   4.6332,  27.9746,  -5.7652,  26.5953,   3.8623,\n",
       "         -12.1401,  -7.3063,  25.7088,   7.1268,  13.8138,  10.4985,  22.2109,\n",
       "          10.4615,  11.3154,  24.7482,   3.4151,  -0.9278,  25.4153,  31.0019,\n",
       "           2.1628,  21.3221,  15.6051,  11.0922,  -6.8726,   8.3026,  16.8213,\n",
       "           2.9926,   8.1325,   9.4760,  -9.2109,  13.8579,  19.5858,  41.1380,\n",
       "          16.4197,  21.3555,  23.7364,  24.5721,  26.0832,  32.2735,  15.6784,\n",
       "          10.2610, -16.3165,  16.9296,   1.3959,   9.2392,  10.8814,   8.8608,\n",
       "           8.5342,  25.5893,  18.7328,  18.6047,  36.4989,  15.7613,   3.1494,\n",
       "          -0.1400,  -4.3095,  24.3532,  26.7317,  24.2752,  15.3345,  39.5954,\n",
       "          13.3157,   2.0965,  35.8320,  15.9056,  18.6806,  23.6851,  24.7479,\n",
       "           4.7174,  16.7907,  -6.8179,  -1.0141, -11.5003,   2.8064,  17.7432,\n",
       "           2.7756,   7.1883]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import encoder\n",
    "import torch\n",
    "\n",
    "mpnn_configs = [mpnn.Config(node_out_feats=16,\n",
    "                 edge_hidden_feats=8, num_step_message_passing=5), mpnn.Config(node_out_feats=64,\n",
    "                 edge_hidden_feats=32, num_step_message_passing=3), mpnn.Config(node_out_feats=128,\n",
    "                 edge_hidden_feats=64, num_step_message_passing=1)]\n",
    "config = {\"mpnn_configs\":mpnn_configs, \"do_two_stage\":True, \"do_edge_update\":True, \"embedding_dim_x\":32, \"embedding_dim_edge_attr\": 64, \"do_edge_update\":True, \"num_sabs\":8,\"dropout\":0.1, \"heads\":8, \"warmup\":.05, \"lr\": 1e-3, \"weight_decay\":.01, \"betas\":(.99,.999)}\n",
    "ex_model = encoder.Encoder(graph_tokenizer=None,**config)\n",
    "ex_model(exmpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "052d0d07-cfe8-4fbf-bcfb-bc9802aa1dac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.6229e+00,  7.0717e+00,  1.8130e+00,  2.9501e+00,  3.0101e+00,\n",
       "         -3.6405e-01,  2.5116e+00,  3.0838e+00,  3.6784e-01,  5.2213e+00,\n",
       "          4.3386e+00,  1.0588e+00,  3.3996e+00,  5.7579e-01,  2.8739e+00,\n",
       "          2.6644e+00,  1.5622e+00,  4.2907e+00,  4.6320e+00,  6.4612e+00,\n",
       "          2.6568e+00,  5.7772e+00,  9.8764e-01,  2.2693e+00,  3.0668e+00,\n",
       "          1.6809e+00,  3.1287e+00,  1.6481e+00,  1.4621e+00,  3.5973e+00,\n",
       "          3.0528e+00,  1.5554e+00,  6.3562e+00,  4.0825e+00,  3.2474e+00,\n",
       "          1.7612e-01, -1.3366e+00,  2.4514e+00,  4.7522e+00,  2.6687e+00,\n",
       "          2.1462e+00,  4.3759e+00,  1.4140e+00, -9.0805e-01,  2.9532e+00,\n",
       "          3.9732e+00,  5.7494e-01,  2.6475e-01,  3.6274e-01,  6.8068e-01,\n",
       "          3.2150e+00,  3.8738e+00,  4.3919e-03,  1.5392e+00,  2.5508e+00,\n",
       "          1.4269e+00,  3.5355e+00, -7.4297e-02,  2.2697e-01,  2.7027e+00,\n",
       "         -2.5722e-01,  2.2003e+00,  2.0599e+00,  2.4785e-01]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpnn_configs = [mpnn.Config(node_out_feats=64,\n",
    "                 edge_hidden_feats=32, num_step_message_passing=3)]\n",
    "config = {\"mpnn_configs\":mpnn_configs,  \"do_two_stage\":False, \"embedding_dim_x\":32, \"embedding_dim_edge_attr\": 64, \"do_edge_update\":False, \"num_sabs\":8,\"dropout\":0.1, \"heads\":8, \"warmup\":.05, \"lr\": 1e-3, \"weight_decay\":.01, \"betas\":(.99,.999)}\n",
    "ex_model = encoder.Encoder(graph_tokenizer=graph_tokenizer,**config)\n",
    "exmpl_tokenized_graph = graph_tokenizer.tokenize(all_data[0][\"graph1\"])\n",
    "ex_model(exmpl_tokenized_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
