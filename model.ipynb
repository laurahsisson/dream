{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3077ca49-b9e7-4fb0-a3a1-bd7c25ce26a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tokenizer\n",
    "import torch\n",
    "\n",
    "graph_tokenizer = tokenizer.GraphTokenizer(torch.load(\"dictionary.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5230b142-7b8d-43d8-bbcf-09e224afab87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 500/500 [00:00<00:00, 1108.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'graph1': BlendData(x=[254, 9], edge_index=[2, 476], edge_attr=[476, 3], blend_batch=[28], mol_batch=[254]),\n",
       " 'graph2': BlendData(x=[239, 9], edge_index=[2, 452], edge_attr=[452, 3], blend_batch=[28], mol_batch=[239]),\n",
       " 'y': tensor(0.5769)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import data\n",
    "import torch_geometric as tg\n",
    "\n",
    "all_data = []\n",
    "with h5py.File('Data/train.h5', 'r') as f:\n",
    "    for label in tqdm.tqdm(f.keys()):\n",
    "        group = f[label]\n",
    "        graph1 = data.read_graph(group['graph1'])\n",
    "        graph2 = data.read_graph(group['graph2'])\n",
    "        # Index using () for scalar dataset\n",
    "        y = group[\"y\"][()]\n",
    "        all_data.append({\"graph1\":graph1,\"graph2\":graph2,\"y\":torch.tensor(y)})\n",
    "\n",
    "all_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3cba35-3131-4003-badd-948fac53d66e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlendData(x=[254], edge_index=[2, 476], edge_attr=[476], blend_batch=[28], mol_batch=[254])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tokenizer.tokenize(all_data[0][\"graph1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e69607-d2d3-4061-9e13-bd2bc6401ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9])\n",
      "torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "import aggregate\n",
    "\n",
    "agg = aggregate.BlendAggregator(True,9,1,1,0)\n",
    "from torch_geometric.loader import DataLoader\n",
    "batch = next(iter(DataLoader([all_data[0][\"graph1\"],all_data[0][\"graph2\"]],batch_size=2)))\n",
    "print(agg(batch.x,batch).shape)\n",
    "print(agg(all_data[0][\"graph1\"].x,all_data[0][\"graph1\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a0f70a-86f6-48ee-bbf6-b91316daf606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9])\n",
      "torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "import aggregate\n",
    "\n",
    "agg = aggregate.BlendAggregator(False,9,1,1,0)\n",
    "from torch_geometric.loader import DataLoader\n",
    "batch = next(iter(DataLoader([all_data[0][\"graph1\"],all_data[0][\"graph2\"]],batch_size=2)))\n",
    "print(agg(batch.x,batch).shape)\n",
    "print(agg(all_data[0][\"graph1\"].x,all_data[0][\"graph1\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e7f2dcb-0f2a-4b1a-a6a0-2e1cd0eca8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0061,  0.0380, -0.2471,  ..., -0.3648,  0.1038,  0.2279],\n",
       "         [-0.2348, -0.0865, -0.1775,  ..., -0.3918,  0.0007, -0.0456],\n",
       "         [-0.1419, -0.0472, -0.2339,  ..., -0.4211,  0.0457,  0.1520],\n",
       "         ...,\n",
       "         [-0.0000, -0.0282, -0.0769,  ..., -0.3449,  0.2760, -0.0175],\n",
       "         [-0.1764, -0.1300, -0.0935,  ..., -0.4022,  0.1159,  0.0821],\n",
       "         [ 0.0129,  0.0000, -0.2097,  ..., -0.3474,  0.1487,  0.2154]],\n",
       "        grad_fn=<MulBackward0>),\n",
       " tensor([[-0.0000, -0.2004,  0.2614,  ...,  0.1953, -0.0359,  0.0978],\n",
       "         [-0.0358, -0.1888,  0.0000,  ...,  0.1675, -0.0655,  0.0000],\n",
       "         [-0.0336, -0.1829,  0.2747,  ...,  0.1635, -0.0626,  0.0949],\n",
       "         ...,\n",
       "         [-0.0365, -0.2037,  0.2410,  ...,  0.1521, -0.0518,  0.0906],\n",
       "         [-0.0170, -0.2200,  0.2573,  ...,  0.1755, -0.0749,  0.0433],\n",
       "         [-0.0000, -0.2078,  0.2550,  ...,  0.1729, -0.0000,  0.0830]],\n",
       "        grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mpnn\n",
    "\n",
    "config = mpnn.Config(node_out_feats=16,\n",
    "                 edge_hidden_feats=16, num_step_message_passing=3)\n",
    "model = mpnn.from_config(config,node_in_feats=9, edge_in_feats=3,dropout=.1, do_edge_update=True)\n",
    "exmpl = all_data[0][\"graph1\"]\n",
    "model(exmpl,exmpl.x,exmpl.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c24bc1dd-5210-45c8-8bb1-a8615e7fe1a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': '12,224',\n",
       " 'base': '6,480',\n",
       " 'project_edge_feats': '64',\n",
       " 'edge_update_network': '1,056',\n",
       " 'gnn_layer': '4,624'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "utils.readout_counts(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb40fa2f-d978-48ba-bd80-aa02a7061ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.7581,  -0.0954,  22.0972,   1.3918,   9.3610,   8.2376,   3.7030,\n",
       "          -7.3447,   1.8093,  24.4488,  22.8326,  25.0683,  10.9185,  15.5346,\n",
       "          25.4530,  -0.4636,  22.9850,  11.8873,   6.6919,  11.7493,  12.8346,\n",
       "          25.8173,  14.5051,  -3.9931,   4.9809,  -0.6271,  24.2211,  -1.9439,\n",
       "           5.2912,  11.0629,  -9.5516,  17.9782,   3.2383,   7.0570,  28.8752,\n",
       "           9.3216,  -0.3137,  28.7258,  12.2864,   1.6070,  20.6726,  10.6713,\n",
       "          12.6482,   3.1562,  26.2624,  22.5475,  16.7776,  24.5206,  11.5999,\n",
       "           4.4933,  -3.4439,  17.9020,  11.0727,  25.0334,  26.2841,  -5.3051,\n",
       "          11.9627,  10.0281,  13.1333,  13.1051,  15.6307,   8.1171,   9.0696,\n",
       "          -2.6088,  -2.1163,  31.6892,   8.3284,  -0.5623,   5.5673,   9.2366,\n",
       "           5.8159,   3.9972,  25.4645,  29.3814,  23.7107,   3.1713,  14.8862,\n",
       "          13.1169,  11.0825,   9.8003,   9.1494,   7.2493,   5.1378,  12.6467,\n",
       "          33.3584,   2.6590,   3.1000,   3.9050,  21.8907,  21.3598,   1.9273,\n",
       "           7.1854,   8.7394,  -4.1547,  16.3147,   6.9481,  25.3325,  23.2984,\n",
       "           9.1191, -12.1476,  12.9074,   0.0639,  19.9797,  12.4433,   6.7989,\n",
       "          -1.4043,  15.3610,  -1.3151,  12.9809,   2.5583,   2.7215,  25.9384,\n",
       "           4.6848,   9.3381,  15.4051,  10.1710,  12.1921,  10.8259,  42.4176,\n",
       "           9.6390,  10.4315,   9.1468,   9.1675,   9.4603,  -6.0827,   6.4247,\n",
       "           2.3489,  12.0837]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import encoder\n",
    "import torch\n",
    "\n",
    "mpnn_configs = [mpnn.Config(node_out_feats=16,\n",
    "                 edge_hidden_feats=8, num_step_message_passing=5), mpnn.Config(node_out_feats=64,\n",
    "                 edge_hidden_feats=32, num_step_message_passing=3), mpnn.Config(node_out_feats=128,\n",
    "                 edge_hidden_feats=64, num_step_message_passing=1)]\n",
    "config = {\"mpnn_configs\":mpnn_configs, \"do_two_stage\":True, \"do_edge_update\":True, \"embedding_dim_x\":32, \"embedding_dim_edge_attr\": 64, \"do_edge_update\":True, \"num_sabs\":8,\"dropout\":0.1, \"heads\":8, \"warmup\":.05, \"lr\": 1e-3, \"weight_decay\":.01, \"betas\":(.99,.999)}\n",
    "ex_model = encoder.Encoder(graph_tokenizer=None,**config)\n",
    "ex_model(exmpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "052d0d07-cfe8-4fbf-bcfb-bc9802aa1dac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7817,  2.3664,  2.5107,  1.4718,  0.1293,  0.3854,  1.5666,  2.9225,\n",
       "          0.3086,  4.7423,  2.5347,  3.4020, -0.0377,  0.0152,  0.8125,  5.3271,\n",
       "          0.4485, -0.2605,  1.5422,  2.2646,  3.4002,  0.6419,  0.4884,  2.3693,\n",
       "          0.1999,  1.1988, -0.4371,  3.1834,  1.1290,  0.2870,  2.7848, -0.9172,\n",
       "          1.6293,  2.7480,  0.7802,  0.6460,  1.4231,  0.9999,  1.5083,  0.1930,\n",
       "          3.3473, -1.7230,  2.3767,  1.5664,  1.5493,  1.2255, -0.0850,  1.4479,\n",
       "          1.3188,  1.2619,  2.5797,  0.9492,  2.9994,  0.3161, -0.2414,  1.8305,\n",
       "          1.5627,  0.2711,  3.0488,  1.7639, -0.5238, -0.9707,  1.1103,  1.0575]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpnn_configs = [mpnn.Config(node_out_feats=64,\n",
    "                 edge_hidden_feats=32, num_step_message_passing=3)]\n",
    "config = {\"mpnn_configs\":mpnn_configs,  \"do_two_stage\":False, \"embedding_dim_x\":32, \"embedding_dim_edge_attr\": 64, \"do_edge_update\":False, \"num_sabs\":8,\"dropout\":0.1, \"heads\":8, \"warmup\":.05, \"lr\": 1e-3, \"weight_decay\":.01, \"betas\":(.99,.999)}\n",
    "ex_model = encoder.Encoder(graph_tokenizer=graph_tokenizer,**config)\n",
    "exmpl_tokenized_graph = graph_tokenizer.tokenize(all_data[0][\"graph1\"])\n",
    "ex_model(exmpl_tokenized_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa70f470-6ee0-4b90-8375-46747f574fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CrossEncoder(torch.nn.Module):\n",
    "    def __init__(self,encoder, do_cosine_similarity, **kwargs):\n",
    "        super(CrossEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.do_cosine_similarity = do_cosine_similarity\n",
    "        if not self.do_cosine_similarity:\n",
    "          self.readout = torch.nn.Linear(self.encoder.readout.in_channels*2,1)\n",
    "\n",
    "    def forward(self,graph1, graph2):\n",
    "      embed1 = self.encoder(graph1)\n",
    "      embed2 = self.encoder(graph2)\n",
    "\n",
    "      if self.do_cosine_similarity:\n",
    "        return torch.nn.functional.cosine_similarity(embed1,embed2)\n",
    "\n",
    "      return torch.nn.functional.sigmoid(self.readout(torch.cat([embed1,embed2],dim=-1))).squeeze(dim=-1)\n",
    "\n",
    "m = CrossEncoder(ex_model,False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
