{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e893eb7f-a4a5-44b4-8628-7cb6a02b9105",
   "metadata": {},
   "source": [
    "# Surprising Pairs\n",
    "**Find the pairs which appear to be the most non-linear in the pair-dataset.**\n",
    "\n",
    "One complication: the set of notes for individual molecules is different from the notes of blend molecules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45229911-5487-4e47-ab39-cfd6d3052dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166814,\n",
       " {'mol1': 'CCCCC/C=C/C(=O)OC',\n",
       "  'mol1_notes': ['violet',\n",
       "   'sweet',\n",
       "   'oily',\n",
       "   'melon',\n",
       "   'pear',\n",
       "   'hairy',\n",
       "   'costus',\n",
       "   'fruity',\n",
       "   'violet leaf',\n",
       "   'waxy',\n",
       "   'fresh',\n",
       "   'green'],\n",
       "  'mol2': 'CCCCCOC(=O)CCC',\n",
       "  'mol2_notes': ['cherry',\n",
       "   'sweet',\n",
       "   'pineapple',\n",
       "   'fruity',\n",
       "   'banana',\n",
       "   'tropical'],\n",
       "  'blend_notes': ['animal', 'fruity', 'waxy']})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the dataset\n",
    "with open(\"data/full.json\") as f:\n",
    "    dataset = json.load(f)\n",
    "len(dataset), dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee337e-cb77-42d1-ae59-32d39a661d84",
   "metadata": {},
   "source": [
    "**Find the set of all notes and encode instances using one hot.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f49668-21d5-42d2-8cd4-43506e69141a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 496)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_blend_notes = set()\n",
    "all_single_notes = set()\n",
    "\n",
    "for d in dataset:\n",
    "    all_blend_notes.update(d[\"blend_notes\"])\n",
    "    all_single_notes.update(d[\"mol1_notes\"])\n",
    "    all_single_notes.update(d[\"mol2_notes\"])\n",
    "\n",
    "all_blend_notes = np.array(list(all_blend_notes))\n",
    "all_single_notes = np.array(list(all_single_notes))\n",
    "len(all_blend_notes), len(all_single_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f96870ed-5110-4ef3-89b6-f56c13381c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot(notes,all_notes):\n",
    "    encode = np.zeros(len(all_notes))\n",
    "    for n in notes:\n",
    "        encode[all_notes.index(n)] = 1\n",
    "    return encode\n",
    "\n",
    "one_hot(dataset[0][\"blend_notes\"], all_blend_notes.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f500dda-e954-41b5-9e26-114bceb8edcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062c6f2782244dcb9cba1857afe7a766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/166814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((166814, 496), (166814, 109))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Using sum for single notes b/c that is more expressive.\n",
    "for d in tqdm(dataset):\n",
    "    X.append(one_hot(d[\"mol1_notes\"], all_single_notes.tolist()) + one_hot(d[\"mol2_notes\"], all_single_notes.tolist()))\n",
    "    y.append(one_hot(d[\"blend_notes\"], all_blend_notes.tolist()))\n",
    "\n",
    "X = np.stack(X)\n",
    "y = np.stack(y)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d79109-2687-49bf-832f-b05cd4869218",
   "metadata": {},
   "source": [
    "**Build logistic regression models to predict blend notes from single notes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b56d611c-5029-4495-81ce-7ab65d83d933",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bcb644e6af452e964a0be70cdfc818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurasisson/miniconda3/envs/rdenv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/laurasisson/miniconda3/envs/rdenv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(109, LogisticRegressionCV(class_weight='balanced', max_iter=1000))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "models = []\n",
    "for idx in tqdm(range(y.shape[1])):\n",
    "    models.append(LogisticRegressionCV(class_weight=\"balanced\",max_iter=1000).fit(X,y[:,idx]))\n",
    "len(models), models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7413e16b-1adf-4f04-922f-616d75d4aa1d",
   "metadata": {},
   "source": [
    "**Calculate predictions and probability of label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9098344b-a180-4c8d-a700-39203f5e51d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8bbaea45f0440d69bd902fc8d4011e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a372a0c31f4f0ca4d78576ee7262fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((166814, 109), (166814, 109))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = np.stack([model.predict_proba(X) for model in tqdm(models)],axis=-1)\n",
    "# Get probability for positive label\n",
    "prob = prob[:,1,:]\n",
    "\n",
    "pred = np.stack([model.predict(X) for model in tqdm(models)],axis=-1)\n",
    "pred.shape, prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08baa50c-e3f1-48d1-80da-70fe935d064c",
   "metadata": {},
   "source": [
    "**Calculate log-likelihood**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7425ec1d-be2d-46de-a700-d21008503fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-12\u001b[39m                               \u001b[38;5;66;03m# numerical safety\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# y is sparse\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m y_dense   \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m      7\u001b[0m logloss_each \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(\n\u001b[1;32m      8\u001b[0m         y_dense \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(prob \u001b[38;5;241m+\u001b[39m eps) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m      9\u001b[0m         (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y_dense) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m prob \u001b[38;5;241m+\u001b[39m eps),\n\u001b[1;32m     10\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)                           \u001b[38;5;66;03m# shape (n_samples,)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m logloss_each\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "# ---------- choose a loss / residual ----------\n",
    "eps = 1e-12                               # numerical safety\n",
    "\n",
    "# y is sparse\n",
    "y_dense   = y.toarray()\n",
    "logloss_each = -np.sum(\n",
    "        y_dense * np.log(prob + eps) +\n",
    "        (1 - y_dense) * np.log(1 - prob + eps),\n",
    "        axis=1)                           # shape (n_samples,)\n",
    "logloss_each.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64027e50-2a36-4a3c-bc9d-ba44a51ef678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.hist(np.exp(-logloss_each))\n",
    "plt.hist(logloss_each)\n",
    "plt.title(\"Distribution of Negative Log-Likelihood\\nby Logistic-Regression Model\")\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.xlabel(\"Negative Log-likelihood of Ground-Truth Labels\")\n",
    "plt.ylabel(\"Frequency (log-scale)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0ce763-e2ee-44df-8a10-ed3d5c277f01",
   "metadata": {},
   "source": [
    "**Sort by least-likely and generate output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55232a32-a814-4c82-ba89-917635957bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "sorted_indices = np.argsort(-logloss_each)\n",
    "top_k = 100\n",
    "output_dataset = []\n",
    "\n",
    "for idx in sorted_indices[:top_k]:\n",
    "    output = copy.deepcopy(dataset[idx])\n",
    "    \n",
    "    # Put predictions into the output entry\n",
    "    output[\"pred_blend\"] = all_blend_notes[np.where(pred[idx]==1)].tolist()\n",
    "    output[\"log-likelihood\"] = logloss_each[idx]\n",
    "    \n",
    "    # Sort both lists for clarity\n",
    "    output[\"blend_notes\"] = sorted(output[\"blend_notes\"])\n",
    "    output[\"pred_blend\"] = sorted(output[\"pred_blend\"])\n",
    "    \n",
    "    output_dataset.append(output)\n",
    "\n",
    "len(output_dataset), output_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a3c60-a0bc-4e86-ba70-e20f97257215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"Output/unlikely_pairs.json\",\"w\") as f:\n",
    "    json.dump(output_dataset,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
